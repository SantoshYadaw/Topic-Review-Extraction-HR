{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b941e2-4a11-4b7d-a955-ead41a4fe4bd",
   "metadata": {},
   "source": [
    "# 02 - Topic Modeling\n",
    "\n",
    "Author: Santosh Yadaw\n",
    "Email: santoshyadawprl@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f33ccf-f1fe-4011-ba36-60c3fd131000",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de624448-7aba-4fd3-bd34-a46b40a9b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c50d11d-2bdd-4149-a4bc-9052f7c84c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: /home/jupyter/Topic-Review-Extraction-HR\n",
      "DATA_FOLDER: /home/jupyter/Topic-Review-Extraction-HR/data/raw\n",
      "FINAL_DATA_FOLDER: /home/jupyter/Topic-Review-Extraction-HR/data/processed\n",
      "RAW_DATA_PATH: /home/jupyter/Topic-Review-Extraction-HR/data/raw/DS2-assessment-simulated-employee-text.xlsx\n",
      "FINAL_DATA_PATH: /home/jupyter/Topic-Review-Extraction-HR/data/processed/processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "BASE_DIR = os.path.dirname(os.getcwd()) \n",
    "print(f\"BASE_DIR: {BASE_DIR}\")\n",
    "\n",
    "DATA_FOLDER = os.path.join(BASE_DIR,\"data\", \"raw\")\n",
    "print(f\"DATA_FOLDER: {DATA_FOLDER}\")\n",
    "\n",
    "FINAL_DATA_FOLDER = os.path.join(BASE_DIR,\"data\", \"processed\")\n",
    "print(f\"FINAL_DATA_FOLDER: {FINAL_DATA_FOLDER}\")\n",
    "\n",
    "RAW_DATA_PATH = os.path.join(DATA_FOLDER, \"DS2-assessment-simulated-employee-text.xlsx\")\n",
    "print(f\"RAW_DATA_PATH: {RAW_DATA_PATH}\")\n",
    "\n",
    "FINAL_DATA_PATH = os.path.join(FINAL_DATA_FOLDER, \"processed_data.csv\")\n",
    "print(f\"FINAL_DATA_PATH: {FINAL_DATA_PATH}\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83589f76-0aba-4194-8feb-f91c7a3b059d",
   "metadata": {},
   "source": [
    "## 2. Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbee63c8-e95a-41a9-919a-8b7afdfad120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_identifier</th>\n",
       "      <th>employee_feedback</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3565</td>\n",
       "      <td>There's a culture of blame within the company ...</td>\n",
       "      <td>Dept A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7323</td>\n",
       "      <td>The company's approach to feedback and perform...</td>\n",
       "      <td>Dept A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5008</td>\n",
       "      <td>While page limits have been set, some departme...</td>\n",
       "      <td>Dept A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3460</td>\n",
       "      <td>na</td>\n",
       "      <td>Dept A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2179</td>\n",
       "      <td>The culture of collaboration within our team i...</td>\n",
       "      <td>Dept A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_identifier                                  employee_feedback  \\\n",
       "0               3565  There's a culture of blame within the company ...   \n",
       "1               7323  The company's approach to feedback and perform...   \n",
       "2               5008  While page limits have been set, some departme...   \n",
       "3               3460                                                 na   \n",
       "4               2179  The culture of collaboration within our team i...   \n",
       "\n",
       "  department  \n",
       "0     Dept A  \n",
       "1     Dept A  \n",
       "2     Dept A  \n",
       "3     Dept A  \n",
       "4     Dept A  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "raw_data = pd.read_excel(RAW_DATA_PATH)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55aafd64-263c-46e4-a4ec-5f85f4b39cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the wordnet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def process_text(text):\n",
    "    # 1. Convert to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Remove any digits and words containing digits\n",
    "    text = ' '.join([word for word in text.split() if not any(c.isdigit() for c in word)])\n",
    "\n",
    "    # 3. Remove punctuations\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # 4. Remove unicode characters\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
    "    \n",
    "    # 5. Remove extrace spaces\n",
    "    text = re.sub(' +', ' ', text).strip()\n",
    "\n",
    "    # 6. Remove stop words in English\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # 7. Lemmatize the words\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Apply processing function\n",
    "raw_data['clean_employee_feedback'] = raw_data['employee_feedback'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82f10701-4a30-46de-950c-a69219f5db75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_identifier</th>\n",
       "      <th>employee_feedback</th>\n",
       "      <th>department</th>\n",
       "      <th>clean_employee_feedback</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3565</td>\n",
       "      <td>There's a culture of blame within the company ...</td>\n",
       "      <td>Dept A</td>\n",
       "      <td>there culture blame within company make diffic...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7323</td>\n",
       "      <td>The company's approach to feedback and perform...</td>\n",
       "      <td>Dept A</td>\n",
       "      <td>company approach feedback performance review g...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5008</td>\n",
       "      <td>While page limits have been set, some departme...</td>\n",
       "      <td>Dept A</td>\n",
       "      <td>page limit set department ignoring still long ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2179</td>\n",
       "      <td>The culture of collaboration within our team i...</td>\n",
       "      <td>Dept A</td>\n",
       "      <td>culture collaboration within team truly someth...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6830</td>\n",
       "      <td>While the workload can be overwhelming at time...</td>\n",
       "      <td>Dept A</td>\n",
       "      <td>workload overwhelming time appreciate company ...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>7590</td>\n",
       "      <td>Our documentation is thorough. Onboarding new ...</td>\n",
       "      <td>Dept D</td>\n",
       "      <td>documentation thorough onboarding new member q...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4622</td>\n",
       "      <td>Feedback flows freely. Suggestions to improve ...</td>\n",
       "      <td>Dept D</td>\n",
       "      <td>feedback flow freely suggestion improve seen o...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2635</td>\n",
       "      <td>Our team leads by example. The standards they ...</td>\n",
       "      <td>Dept D</td>\n",
       "      <td>team lead example standard set motivate excel</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>3272</td>\n",
       "      <td>Cross-training and job shadowing help broaden ...</td>\n",
       "      <td>Dept D</td>\n",
       "      <td>crosstraining job shadowing help broaden skill...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>5301</td>\n",
       "      <td>Virtual collaboration tools and communication ...</td>\n",
       "      <td>Dept D</td>\n",
       "      <td>virtual collaboration tool communication chann...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_identifier                                  employee_feedback  \\\n",
       "0                 3565  There's a culture of blame within the company ...   \n",
       "1                 7323  The company's approach to feedback and perform...   \n",
       "2                 5008  While page limits have been set, some departme...   \n",
       "4                 2179  The culture of collaboration within our team i...   \n",
       "5                 6830  While the workload can be overwhelming at time...   \n",
       "..                 ...                                                ...   \n",
       "150               7590  Our documentation is thorough. Onboarding new ...   \n",
       "151               4622  Feedback flows freely. Suggestions to improve ...   \n",
       "152               2635  Our team leads by example. The standards they ...   \n",
       "153               3272  Cross-training and job shadowing help broaden ...   \n",
       "154               5301  Virtual collaboration tools and communication ...   \n",
       "\n",
       "    department                            clean_employee_feedback  word_count  \n",
       "0       Dept A  there culture blame within company make diffic...          25  \n",
       "1       Dept A  company approach feedback performance review g...          85  \n",
       "2       Dept A  page limit set department ignoring still long ...          31  \n",
       "4       Dept A  culture collaboration within team truly someth...          57  \n",
       "5       Dept A  workload overwhelming time appreciate company ...          36  \n",
       "..         ...                                                ...         ...  \n",
       "150     Dept D  documentation thorough onboarding new member q...          14  \n",
       "151     Dept D  feedback flow freely suggestion improve seen o...          12  \n",
       "152     Dept D      team lead example standard set motivate excel          13  \n",
       "153     Dept D  crosstraining job shadowing help broaden skill...          16  \n",
       "154     Dept D  virtual collaboration tool communication chann...          15  \n",
       "\n",
       "[135 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any samples with less than 1 words\n",
    "raw_data[\"word_count\"] = raw_data['employee_feedback'].apply(lambda x : len(x.split()))\n",
    "data_final = raw_data[raw_data[\"word_count\"] > 1]\n",
    "data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1de1d70b-36e0-4f9b-a228-da4804cbb312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as final data\n",
    "data_final.to_csv(FINAL_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d1ac7c-5ee4-4c1f-b2c3-1cea0b262ade",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bcb929-1505-494b-bd5f-6a4abbc2e984",
   "metadata": {},
   "source": [
    "### 3.1 Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "A popular method for topic method that helps identify overarching topics in the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994e7f9-2208-4804-a0cb-93f792d66602",
   "metadata": {},
   "source": [
    "#### 3.1.1 All response LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "911386fd-3741-440f-94b3-e991ffccb1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.019*\"company\" + 0.016*\"work\" + 0.010*\"good\" + 0.008*\"balance\" + 0.008*\"feel\" + 0.008*\"process\" + 0.007*\"expectation\" + 0.006*\"available\" + 0.006*\"worklife\" + 0.006*\"make\"\n",
      "Topic: 1 \n",
      "Words: 0.022*\"work\" + 0.016*\"company\" + 0.014*\"feedback\" + 0.012*\"employee\" + 0.010*\"would\" + 0.010*\"difficult\" + 0.009*\"lack\" + 0.009*\"like\" + 0.008*\"need\" + 0.008*\"workload\"\n",
      "Topic: 2 \n",
      "Words: 0.033*\"feel\" + 0.030*\"company\" + 0.017*\"work\" + 0.015*\"team\" + 0.014*\"like\" + 0.009*\"would\" + 0.009*\"goal\" + 0.008*\"employee\" + 0.008*\"manager\" + 0.008*\"appreciate\"\n",
      "Topic: 3 \n",
      "Words: 0.012*\"work\" + 0.008*\"make\" + 0.008*\"effort\" + 0.008*\"still\" + 0.007*\"difficult\" + 0.007*\"workload\" + 0.007*\"everyone\" + 0.006*\"even\" + 0.006*\"company\" + 0.006*\"level\"\n",
      "Topic: 4 \n",
      "Words: 0.023*\"company\" + 0.015*\"employee\" + 0.013*\"work\" + 0.013*\"would\" + 0.012*\"help\" + 0.010*\"could\" + 0.009*\"feel\" + 0.009*\"like\" + 0.008*\"investment\" + 0.007*\"make\"\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(raw_data['clean_employee_feedback'].str.split())\n",
    "corpus = [dictionary.doc2bow(text.split()) for text in raw_data['clean_employee_feedback']]\n",
    "lda = LdaModel(corpus, id2word=dictionary, num_topics=5) # adjust num_topics based on your needs\n",
    "\n",
    "# Displaying topics\n",
    "for idx, topic in lda.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936e42d-1a22-40cb-ad58-03f841a82db7",
   "metadata": {},
   "source": [
    "#### 3.1.2 LDA by Department\n",
    "\n",
    "For specific concerns by different departments, we can segment the data by department and conduct topic modeling (LDA) for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8892dfe4-b92a-427d-b557-f02a25630095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics for department Dept A:\n",
      "Topic: 0 \n",
      "Words: 0.020*\"company\" + 0.012*\"work\" + 0.012*\"package\" + 0.011*\"benefit\" + 0.010*\"feel\" + 0.009*\"employee\" + 0.009*\"offer\" + 0.008*\"workload\" + 0.006*\"like\" + 0.006*\"area\"\n",
      "Topic: 1 \n",
      "Words: 0.023*\"company\" + 0.013*\"feel\" + 0.013*\"like\" + 0.010*\"appreciate\" + 0.010*\"could\" + 0.008*\"work\" + 0.008*\"employee\" + 0.008*\"however\" + 0.008*\"concern\" + 0.007*\"na\"\n",
      "Topic: 2 \n",
      "Words: 0.020*\"company\" + 0.014*\"work\" + 0.008*\"employee\" + 0.008*\"success\" + 0.008*\"incredibly\" + 0.008*\"feel\" + 0.008*\"available\" + 0.007*\"manager\" + 0.007*\"goal\" + 0.007*\"share\"\n",
      "Topic: 3 \n",
      "Words: 0.015*\"company\" + 0.011*\"feedback\" + 0.009*\"make\" + 0.009*\"difficult\" + 0.009*\"mistake\" + 0.005*\"review\" + 0.005*\"health\" + 0.005*\"approach\" + 0.005*\"performance\" + 0.005*\"work\"\n",
      "Topic: 4 \n",
      "Words: 0.015*\"feedback\" + 0.008*\"would\" + 0.008*\"work\" + 0.007*\"make\" + 0.007*\"something\" + 0.007*\"manager\" + 0.007*\"everyone\" + 0.007*\"issue\" + 0.006*\"employee\" + 0.006*\"performance\"\n",
      "\n",
      "Topics for department Dept B:\n",
      "Topic: 0 \n",
      "Words: 0.010*\"employee\" + 0.009*\"company\" + 0.009*\"would\" + 0.007*\"opportunity\" + 0.007*\"positive\" + 0.006*\"working\" + 0.006*\"help\" + 0.006*\"management\" + 0.006*\"like\" + 0.005*\"feel\"\n",
      "Topic: 1 \n",
      "Words: 0.011*\"company\" + 0.011*\"would\" + 0.010*\"like\" + 0.009*\"area\" + 0.006*\"frequent\" + 0.006*\"goal\" + 0.006*\"feel\" + 0.005*\"still\" + 0.005*\"information\" + 0.005*\"could\"\n",
      "Topic: 2 \n",
      "Words: 0.003*\"precious\" + 0.003*\"ever\" + 0.003*\"area\" + 0.003*\"would\" + 0.003*\"error\" + 0.003*\"margin\" + 0.002*\"increasing\" + 0.002*\"direction\" + 0.002*\"time\" + 0.002*\"becomes\"\n",
      "Topic: 3 \n",
      "Words: 0.016*\"company\" + 0.010*\"work\" + 0.010*\"everyone\" + 0.010*\"would\" + 0.008*\"goal\" + 0.008*\"direction\" + 0.008*\"clear\" + 0.007*\"employee\" + 0.007*\"feel\" + 0.007*\"appreciate\"\n",
      "Topic: 4 \n",
      "Words: 0.012*\"company\" + 0.010*\"feel\" + 0.010*\"employee\" + 0.007*\"want\" + 0.007*\"around\" + 0.007*\"career\" + 0.007*\"guidance\" + 0.007*\"would\" + 0.007*\"like\" + 0.006*\"decision\"\n",
      "\n",
      "Topics for department Dept C:\n",
      "Topic: 0 \n",
      "Words: 0.015*\"company\" + 0.014*\"feel\" + 0.011*\"difficult\" + 0.010*\"available\" + 0.010*\"feedback\" + 0.009*\"like\" + 0.009*\"receive\" + 0.008*\"work\" + 0.008*\"balance\" + 0.007*\"would\"\n",
      "Topic: 1 \n",
      "Words: 0.010*\"feel\" + 0.010*\"process\" + 0.009*\"good\" + 0.008*\"career\" + 0.007*\"etc\" + 0.006*\"plus\" + 0.006*\"growth\" + 0.006*\"company\" + 0.006*\"organization\" + 0.006*\"team\"\n",
      "Topic: 2 \n",
      "Words: 0.011*\"company\" + 0.008*\"opportunity\" + 0.008*\"limited\" + 0.008*\"growth\" + 0.008*\"employee\" + 0.007*\"staff\" + 0.006*\"policy\" + 0.006*\"management\" + 0.006*\"difficult\" + 0.006*\"lack\"\n",
      "Topic: 3 \n",
      "Words: 0.035*\"work\" + 0.024*\"feel\" + 0.021*\"company\" + 0.013*\"team\" + 0.011*\"like\" + 0.011*\"make\" + 0.011*\"would\" + 0.010*\"within\" + 0.010*\"employee\" + 0.010*\"could\"\n",
      "Topic: 4 \n",
      "Words: 0.013*\"company\" + 0.011*\"work\" + 0.009*\"feel\" + 0.008*\"effort\" + 0.006*\"goal\" + 0.004*\"pressure\" + 0.004*\"one\" + 0.004*\"valued\" + 0.004*\"opinion\" + 0.004*\"balance\"\n",
      "\n",
      "Topics for department Dept D:\n",
      "Topic: 0 \n",
      "Words: 0.006*\"issue\" + 0.006*\"arise\" + 0.006*\"ensure\" + 0.006*\"adjustment\" + 0.006*\"track\" + 0.006*\"quickly\" + 0.006*\"checkins\" + 0.006*\"made\" + 0.006*\"regular\" + 0.001*\"team\"\n",
      "Topic: 1 \n",
      "Words: 0.013*\"team\" + 0.010*\"work\" + 0.009*\"help\" + 0.007*\"needed\" + 0.007*\"improve\" + 0.007*\"collaboration\" + 0.007*\"flexibility\" + 0.007*\"balance\" + 0.007*\"time\" + 0.006*\"report\"\n",
      "Topic: 2 \n",
      "Words: 0.014*\"team\" + 0.009*\"everyone\" + 0.009*\"idea\" + 0.009*\"valued\" + 0.009*\"effort\" + 0.009*\"feel\" + 0.007*\"priority\" + 0.006*\"however\" + 0.005*\"future\" + 0.005*\"set\"\n",
      "Topic: 3 \n",
      "Words: 0.015*\"team\" + 0.012*\"member\" + 0.008*\"schedule\" + 0.008*\"practice\" + 0.008*\"shared\" + 0.008*\"knowledge\" + 0.007*\"best\" + 0.007*\"purpose\" + 0.007*\"sense\" + 0.006*\"commitment\"\n",
      "Topic: 4 \n",
      "Words: 0.008*\"make\" + 0.007*\"team\" + 0.006*\"member\" + 0.006*\"decision\" + 0.006*\"individual\" + 0.006*\"logically\" + 0.006*\"optimized\" + 0.006*\"result\" + 0.006*\"responsibility\" + 0.006*\"effectively\"\n"
     ]
    }
   ],
   "source": [
    "departments = raw_data['department'].unique()\n",
    "\n",
    "for dept in departments:\n",
    "    dept_df = raw_data[raw_data['department'] == dept]\n",
    "    dept_corpus = [dictionary.doc2bow(text.split()) for text in dept_df['clean_employee_feedback']]\n",
    "    \n",
    "    dept_lda = LdaModel(dept_corpus, id2word=dictionary, num_topics=5) # adjust num_topics if needed\n",
    "    \n",
    "    print(f\"\\nTopics for department {dept}:\")\n",
    "    for idx, topic in dept_lda.print_topics(-1):\n",
    "        print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d4b69c-1381-44c7-aedb-44c1c9d5c97c",
   "metadata": {},
   "source": [
    "#### 3.1.3 Infer profile individuals\n",
    "\n",
    "To deduce the profile, we can try to cluster employees based on their topic wieghts from the LDA model, suggesting those with similar topic weights might have similar sentiments or converns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6a041e2-4b97-4608-bbdd-63cdafaca666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample responses from Cluster 0:\n",
      "82     appreciate flexibility offered company sometim...\n",
      "9      company benefit package generally competitive ...\n",
      "59     worklife balance option excellent whether need...\n",
      "77     appreciate company commitment diversity inclus...\n",
      "144    team celebrates win together maintains momentu...\n",
      "Name: clean_employee_feedback, dtype: object\n",
      "Sample responses from Cluster 1:\n",
      "105           career advancement depends managerial whim\n",
      "43     opendoor policy management willingness listen ...\n",
      "41     relook benchmarking investment bank compensati...\n",
      "24                                                    na\n",
      "53     would help create positive motivated work envi...\n",
      "Name: clean_employee_feedback, dtype: object\n",
      "Sample responses from Cluster 2:\n",
      "133    clear objective set everyone understood goal p...\n",
      "21     however doesnt seem much encouragement share m...\n",
      "2      page limit set department ignoring still long ...\n",
      "40                                                      \n",
      "27                                                      \n",
      "Name: clean_employee_feedback, dtype: object\n",
      "Sample responses from Cluster 3:\n",
      "64     feel like communication issue within team frus...\n",
      "84     salary structure transparent fair feel hard wo...\n",
      "108                                   proud work company\n",
      "83     walking talk showing empathy handson staff bac...\n",
      "141    diverse perspective within team allow u gain f...\n",
      "Name: clean_employee_feedback, dtype: object\n",
      "Sample responses from Cluster 4:\n",
      "142    good balance structure creativity process enab...\n",
      "148    conflict handled constructively difference opi...\n",
      "35     demonstrating trust allowing flexible working ...\n",
      "80       decisiveness dare challenge norm transformative\n",
      "70     lot process streamlining achieved past year eg...\n",
      "Name: clean_employee_feedback, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/topic-extract/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Extracting topic distributions for each response\n",
    "topic_weights = [lda.get_document_topics(item, minimum_probability=0) for item in corpus]\n",
    "topic_distr = np.array([[weight for _, weight in item] for item in topic_weights])\n",
    "\n",
    "# Clustering using KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42).fit(topic_distr) # adjust the number of clusters based on your needs\n",
    "\n",
    "# Attaching cluster labels to df\n",
    "raw_data['cluster'] = kmeans.labels_\n",
    "\n",
    "# You can then analyze each cluster, exploring potential profiles. Example:\n",
    "for cluster_num in range(5): # adjust based on the number of clusters used\n",
    "    cluster_data = raw_data[raw_data['cluster'] == cluster_num]\n",
    "    print(f\"Sample responses from Cluster {cluster_num}:\")\n",
    "    print(cluster_data['clean_employee_feedback'].sample(5)) # showing 5 sample responses from the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354cdfde-43ea-49f8-9838-058e63ab88a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "topic-extract",
   "name": "pytorch-gpu.1-11.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m93"
  },
  "kernelspec": {
   "display_name": "topic-extract",
   "language": "python",
   "name": "topic-extract"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
